# è´¨æ§äº‘çœ¼---åŸºäºåä¸ºé¦™æ©™æ´¾äº‘è´¨æ£€ä¸€ä½“ç³»ç»Ÿ

> æœ¬é¡¹ç›®çš„æŠ€æœ¯ç›®çš„èšç„¦äºç ´è§£å½“å‰å·¥ä¸šç¼ºé™·æ£€æµ‹é¢†åŸŸçš„æ ¸å¿ƒç—›ç‚¹ï¼Œé€šè¿‡é’ˆå¯¹æ€§çš„ç®—æ³•åˆ›æ–°ä¸æ¶æ„è®¾è®¡ï¼Œå®ç°æ£€æµ‹ç²¾åº¦ã€åœºæ™¯é€‚åº”æ€§ä¸éƒ¨ç½²æ•ˆç‡çš„å…¨æ–¹ä½æå‡ï¼Œä¸ºå¤æ‚å·¥ä¸šç¯å¢ƒä¸‹çš„è´¨é‡æ§åˆ¶æä¾›å¯é æŠ€æœ¯æ”¯æ’‘ã€‚

[![License](https://img.shields.io/badge/License-GPLv3-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/python-3.11%2B-blue.svg)]()  ![MindSpore](https://img.shields.io/badge/MindSpore-2.7.0-blue.svg)


---

# ç›®å½•ï¼ˆTable of Contentsï¼‰

- [è´¨æ§äº‘çœ¼---åŸºäºåä¸ºé¦™æ©™æ´¾äº‘è´¨æ£€ä¸€ä½“ç³»ç»Ÿ](#è´¨æ§äº‘çœ¼---åŸºäºåä¸ºé¦™æ©™æ´¾äº‘è´¨æ£€ä¸€ä½“ç³»ç»Ÿ)
- [ç›®å½•ï¼ˆTable of Contentsï¼‰](#ç›®å½•table-of-contents)
- [ç‰¹æ€§ï¼ˆFeaturesï¼‰](#ç‰¹æ€§features)
- [å¿«é€Ÿå¼€å§‹ï¼ˆQuick Startï¼‰](#å¿«é€Ÿå¼€å§‹quick-start)
- [é¡¹ç›®ç»“æ„ï¼ˆProject Structureï¼‰](#é¡¹ç›®ç»“æ„project-structure)
- [å®‰è£…ï¼ˆInstallationï¼‰](#å®‰è£…installation)
  - [æ–¹å¼ä¸€ï¼šCondaï¼ˆæ¨èï¼‰](#æ–¹å¼ä¸€condaæ¨è)
  - [æ–¹å¼äºŒï¼špip](#æ–¹å¼äºŒpip)
  - [Dockerï¼ˆå¯é€‰ï¼‰](#dockerå¯é€‰)
- [æ•°æ®é›†ï¼ˆDatasetï¼‰](#æ•°æ®é›†dataset)
- [è®­ç»ƒï¼ˆTrainingï¼‰](#è®­ç»ƒtraining)
  - [æ ¸å¿ƒå‘½ä»¤](#æ ¸å¿ƒå‘½ä»¤)
  - [å¸¸è§å¯é€‰é¡¹ï¼ˆexamplesï¼‰](#å¸¸è§å¯é€‰é¡¹examples)
  - [æ—¥å¿—ä¸ç›‘æ§](#æ—¥å¿—ä¸ç›‘æ§)
- [è¯„ä¼°ï¼ˆEvaluationï¼‰](#è¯„ä¼°evaluation)
- [æ¨ç†ï¼ˆInferenceï¼‰](#æ¨ç†inference)
- [é…ç½®ï¼ˆConfigurationï¼‰](#é…ç½®configuration)
- [å¸¸ç”¨è¶…å‚è¡¨](#å¸¸ç”¨è¶…å‚è¡¨)
- [æ¨¡å‹ä¸ç»“æœï¼ˆModels \& Resultsï¼‰](#æ¨¡å‹ä¸ç»“æœmodels--results)
- [å¯è§†åŒ–ï¼ˆVisualizationï¼‰](#å¯è§†åŒ–visualization)
- [å•å…ƒæµ‹è¯•ï¼ˆTestingï¼‰](#å•å…ƒæµ‹è¯•testing)
- [æ¨¡å‹å¡ï¼ˆModel Card / Model Card Templateï¼‰](#æ¨¡å‹å¡model-card--model-card-template)
- [è´¡çŒ®ï¼ˆContributingï¼‰](#è´¡çŒ®contributing)
- [å¼•ç”¨ï¼ˆCitationï¼‰](#å¼•ç”¨citation)
- [è®¸å¯ï¼ˆLicenseï¼‰](#è®¸å¯license)
- [å˜æ›´æ—¥å¿—ï¼ˆChangelogï¼‰](#å˜æ›´æ—¥å¿—changelog)

---

# ç‰¹æ€§ï¼ˆFeaturesï¼‰

- âœ… æ”¯æŒ CPU / åä¸ºæ˜‡è…¾ NPUè®­ç»ƒ
- âš¡ æä¾›è®­ç»ƒã€éªŒè¯ä¸æ¨ç†å®Œæ•´æµæ°´çº¿
- ğŸ”§ ä½¿ç”¨ç»Ÿä¸€TOMLé…ç½®ï¼Œç®€å•æ˜“ç”¨
- ğŸ“¦ é«˜åº¦æ¨¡å—åŒ–ï¼Œæ˜“äºç»´æŠ¤
- ğŸ§ª æœ‰è‰¯å¥½çš„æ£€æµ‹ç²¾ç¡®åº¦å’Œæ³›åŒ–æ€§

---

# å¿«é€Ÿå¼€å§‹ï¼ˆQuick Startï¼‰

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/<yourname>/<repo>.git
cd <repo>

# å»ºè®®ä½¿ç”¨ conda
conda env create -f environment.yml
conda activate <env_name>

# ä¸‹è½½/å‡†å¤‡æ•°æ®ï¼ˆè§ Data sectionï¼‰
bash scripts/download_data.sh

# è®­ç»ƒï¼ˆå•å¡ï¼‰
python tools/train.py --config configs/exp1.yaml

# æ¨ç†/è¯„ä¼°
python tools/eval.py --config configs/exp1.yaml --ckpt checkpoints/exp1_latest.pth
python tools/infer.py --config configs/exp1.yaml --input examples/img.jpg --output results/out.jpg
```

---

# é¡¹ç›®ç»“æ„ï¼ˆProject Structureï¼‰

```
<repo>/
â”œâ”€â”€ README.md
â”œâ”€â”€ environment.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ exp1.yaml
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ download_data.sh
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/  # ä¸‹è½½/æŒ‚è½½æ•°æ®
â”œâ”€â”€ datasets/  # æ•°æ®å¤„ç†ã€Dataset ç±»
â”œâ”€â”€ models/    # æ¨¡å‹å®šä¹‰
â”œâ”€â”€ trainers/  # è®­ç»ƒå™¨ã€è¯„ä¼°å™¨
â”œâ”€â”€ tools/     # train.py / eval.py / infer.py
â”œâ”€â”€ checkpoints/
â”œâ”€â”€ docs/
â””â”€â”€ tests/
```

---

# å®‰è£…ï¼ˆInstallationï¼‰

## æ–¹å¼ä¸€ï¼šCondaï¼ˆæ¨èï¼‰

```bash
conda env create -f environment.yml
conda activate <env_name>
```

## æ–¹å¼äºŒï¼špip

```bash
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

## Dockerï¼ˆå¯é€‰ï¼‰

```bash
docker build -t <repo>:latest .
docker run --gpus all -v $(pwd):/workspace <repo>:latest
```

---

# æ•°æ®é›†ï¼ˆDatasetï¼‰

- æ•°æ®æ¥æºï¼šè¯´æ˜æ•°æ®é›†åç§°ä¸ä¸‹è½½é“¾æ¥ï¼ˆè‹¥å—é™åˆ™è¯´æ˜è·å–æ–¹å¼ï¼‰
- æ•°æ®æ ¼å¼ï¼šä¾‹å¦‚ `images/` + `annotations/`ï¼Œæˆ– COCO / VOC / custom
- æ•°æ®å‡†å¤‡ç¤ºä¾‹ï¼š

```bash
# å°†åŸå§‹æ•°æ®æ”¾åˆ° data/rawï¼Œç„¶åè¿è¡Œé¢„å¤„ç†è„šæœ¬
python datasets/prepare.py --src data/raw --dst data/processed
```

- åˆ’åˆ†ï¼šè®­ç»ƒ/éªŒè¯/æµ‹è¯• æ¯”ä¾‹æˆ– split æ–‡ä»¶è¯´æ˜

---

# è®­ç»ƒï¼ˆTrainingï¼‰

## æ ¸å¿ƒå‘½ä»¤

```bash
python tools/train.py --config configs/exp1.yaml     --work-dir runs/exp1     --gpus 1     --seed 42
```

## å¸¸è§å¯é€‰é¡¹ï¼ˆexamplesï¼‰

- `--config`ï¼šé…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆYAML/JSONï¼‰
- `--work-dir`ï¼šè¾“å‡ºç›®å½•ï¼ˆcheckpoints/logsï¼‰
- `--resume`ï¼šæ–­ç‚¹æ¢å¤è·¯å¾„
- `--amp`ï¼šæ··åˆç²¾åº¦è®­ç»ƒï¼ˆå¦‚æœæ”¯æŒï¼‰

## æ—¥å¿—ä¸ç›‘æ§

- æ”¯æŒ TensorBoard / Weights & Biasesï¼ˆç¤ºä¾‹ï¼‰

```bash
tensorboard --logdir runs/
```

---

# è¯„ä¼°ï¼ˆEvaluationï¼‰

```bash
python tools/eval.py --config configs/exp1.yaml --ckpt checkpoints/best.pth --metrics mAP,precision,recall
```

- è¾“å‡ºï¼šè¯„ä¼°æŒ‡æ ‡è¡¨æ ¼ã€æ··æ·†çŸ©é˜µã€P-R æ›²çº¿ç­‰

---

# æ¨ç†ï¼ˆInferenceï¼‰

```bash
python tools/infer.py --config configs/exp1.yaml --ckpt checkpoints/best.pth --input examples/img.jpg --output results/out.jpg
```

ç¤ºä¾‹ APIï¼ˆå¯åµŒå…¥åˆ°æœåŠ¡ï¼‰ï¼š

```python
from models import build_model
model = build_model(cfg.model)
model.load_state_dict(torch.load('checkpoints/best.pth'))
model.eval()
pred = model.predict(image)
```

---

# é…ç½®ï¼ˆConfigurationï¼‰

- ä½¿ç”¨ `configs/*.yaml` ç®¡ç†å®éªŒè¶…å‚ä¸è·¯å¾„ã€‚
- ç¤ºä¾‹ `configs/exp1.yaml`ï¼š

```yaml
name: exp1
seed: 42
model:
  type: resnet50
  pretrained: true
dataset:
  name: mydataset
  root: data/processed
train:
  epochs: 100
  batch_size: 16
  lr: 0.001
  weight_decay: 1e-4
optimizer:
  type: adamw
```

# å¸¸ç”¨è¶…å‚è¡¨

| å‚æ•°       | è¯´æ˜         | ç¤ºä¾‹        |
| ---------- | ------------ | ----------- |
| epochs     | è®­ç»ƒè½®æ•°     | 100         |
| batch_size | æ‰¹å¤§å°       | 16          |
| lr         | åˆå§‹å­¦ä¹ ç‡   | 1e-3        |
| scheduler  | å­¦ä¹ ç‡è°ƒåº¦å™¨ | cosine/step |

---

# æ¨¡å‹ä¸ç»“æœï¼ˆModels & Resultsï¼‰

- æä¾›è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡ï¼ˆcheckpointï¼‰ä¸‹è½½é“¾æ¥æˆ–è¯´æ˜å¦‚ä½•è·å–ã€‚
- ç»“æœç¤ºä¾‹ï¼ˆæŠŠä½ çš„å…³é”®æŒ‡æ ‡æ”¾åœ¨è¿™é‡Œï¼‰ï¼š

```
Model: resnet50-baseline
Dataset: MyDataset v1.0
mAP@0.5: 0.842
Precision: 0.83
Recall: 0.79
```

- è¡¨æ ¼å±•ç¤ºä¸åŒå®éªŒå¯¹æ¯”ï¼ˆå»ºè®®æ”¾åœ¨ `docs/` æˆ– `RESULTS.md`ï¼‰

---

# å¯è§†åŒ–ï¼ˆVisualizationï¼‰

- æä¾›å¯è§†åŒ–è„šæœ¬ï¼š`tools/visualize.py`
- æ”¯æŒï¼šé¢„æµ‹çƒ­åŠ›å›¾ï¼ˆheatmapï¼‰ã€Grad-CAMã€bounding boxesã€é”™è¯¯æ ·æœ¬å±•ç¤º
- ç¤ºä¾‹ï¼š

```bash
python tools/visualize.py --ckpt checkpoints/best.pth --data samples/ --out viz/
```

---

# å•å…ƒæµ‹è¯•ï¼ˆTestingï¼‰

- æ”¾ç½®åœ¨ `tests/`ï¼Œä½¿ç”¨ `pytest`ã€‚

```bash
pytest -q
```

- CIï¼šå¯æä¾› `.github/workflows/ci.yml`ï¼ˆå¯é€‰ï¼‰

---

# æ¨¡å‹å¡ï¼ˆModel Card / Model Card Templateï¼‰

ç®€è¦è®°å½•æ¨¡å‹ç”¨é€”ä¸é™åˆ¶ï¼š

- ç”¨é€”ï¼šæ­¤æ¨¡å‹ç”¨äº X ä»»åŠ¡ï¼ˆéåŒ»ç–—/æ³•å¾‹ç­‰é«˜é£é™©ä»»åŠ¡ï¼‰
- é™åˆ¶ï¼šåœ¨ Y åœºæ™¯ä¸‹æ€§èƒ½ä¸‹é™ï¼Œæˆ–æ•°æ®åå·®é£é™©è¯´æ˜
- ä¼¦ç†è€ƒè™‘ï¼šæ•°æ®éšç§ã€æ½œåœ¨æ»¥ç”¨é£é™©ç­‰

---

# è´¡çŒ®ï¼ˆContributingï¼‰

æ¬¢è¿è´¡çŒ®ï¼å»ºè®®æµç¨‹ï¼š

1. Fork æœ¬ä»“åº“
2. åˆ›å»ºåˆ†æ”¯ `git checkout -b feat/xxx`
3. æäº¤å¹¶æ¨é€ `git push origin feat/xxx`
4. æäº¤ PRï¼ˆæè¿°æ”¹åŠ¨ä¸æµ‹è¯•ï¼‰
5. é€šè¿‡ CI ååˆå¹¶

è´¡çŒ®æŒ‡å—ï¼ˆ`CONTRIBUTING.md`ï¼‰åº”åŒ…å«ä»£ç é£æ ¼ã€æäº¤è§„èŒƒã€å¦‚ä½•å†™å•å…ƒæµ‹è¯•ã€å¦‚ä½•è¿è¡Œ demo ç­‰ã€‚

---

# å¼•ç”¨ï¼ˆCitationï¼‰

å¦‚æœä½ ä½¿ç”¨æœ¬é¡¹ç›®ï¼Œè¯·å¼•ç”¨ï¼š

```
@misc{yourrepo2025,
  title={Project Name: short description},
  author={Your Name},
  year={2025},
  howpublished={\url{https://github.com/yourname/yourrepo}}
}
```

---

# è®¸å¯ï¼ˆLicenseï¼‰

æœ¬é¡¹ç›®é‡‡ç”¨ MIT Licenseã€‚è¯¦è§ `LICENSE` æ–‡ä»¶ã€‚

---

# å˜æ›´æ—¥å¿—ï¼ˆChangelogï¼‰

æŸ¥çœ‹ `CHANGELOG.md` è·å–å†å²ç‰ˆæœ¬æ”¹åŠ¨è®°å½•ã€‚
